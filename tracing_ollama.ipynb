{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15691577",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/19 15:14:54 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...\n",
      "/Users/rajranja/Documents/github/cds-9-group-6/test-code/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using default facebook/roberta-hate-speech-dynabench-r4-target checkpoint\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run capable-trout-893 at: http://0.0.0.0:5001/#/experiments/627109935499678511/runs/9d743b2aad5f499c82cbb85c6c394098\n",
      "üß™ View experiment at: http://0.0.0.0:5001/#/experiments/627109935499678511\n",
      "{'toxicity/v1/mean': np.float64(0.026011325418949127), 'toxicity/v1/variance': np.float64(0.0), 'toxicity/v1/p90': np.float64(0.026011325418949127), 'toxicity/v1/ratio': 0.0, 'flesch_kincaid_grade_level/v1/mean': np.float64(-3.3999999999999986), 'flesch_kincaid_grade_level/v1/variance': np.float64(0.0), 'flesch_kincaid_grade_level/v1/p90': np.float64(-3.3999999999999986), 'ari_grade_level/v1/mean': np.float64(-2.09), 'ari_grade_level/v1/variance': np.float64(0.0), 'ari_grade_level/v1/p90': np.float64(-2.09), 'exact_match/v1': 0.0}\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Example finance QA dataset\n",
    "questions = [\"What was the company‚Äôs revenue in Q2?\"]\n",
    "ground_truth = [\"$25.3B\"]\n",
    "predicted_answers = [\"$25B\"]\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://0.0.0.0:5001/\")\n",
    "mlflow.set_experiment(\"QA_Evaluation\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    data = pd.DataFrame(\n",
    "        {\n",
    "            \"question\": questions,\n",
    "            \"ground_truth\": ground_truth,\n",
    "            \"predicted\": predicted_answers,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Evaluate QA model (removed default evaluators to fix hang)\n",
    "    results = mlflow.evaluate(\n",
    "        data=data,\n",
    "        targets=\"ground_truth\",\n",
    "        predictions=\"predicted\",\n",
    "        model_type=\"question-answering\",\n",
    "        evaluators=[\"default\"],  # This was causing the hang - commented out\n",
    "    )\n",
    "\n",
    "print(results.metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a585d95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mlflow\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import httpx\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# from mlflow.metrics.genai.genai_metric import make_genai_metric\n",
    "# from mlflow.metrics.genai import (\n",
    "#     faithfulness,\n",
    "#     relevance,\n",
    "#     answer_correctness,\n",
    "#     answer_relevance,\n",
    "#     answer_similarity,\n",
    "# )\n",
    "\n",
    "# from mlflow.genai.scorers import (\n",
    "#     RelevanceToQuery,\n",
    "#     RetrievalGroundedness,\n",
    "#     RetrievalRelevance,\n",
    "#     RetrievalSufficiency,\n",
    "#     Safety,\n",
    "#     Guidelines,\n",
    "#     Correctness,\n",
    "#     ExpectationsGuidelines,\n",
    "#     Scorer,\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba99299",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cb64c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_env_vars():\n",
    "    required_env_vars = [\n",
    "        \"OPENAI_API_KEY\",\n",
    "        \"MLFLOW_TRACKING_URI\",\n",
    "        \"MLFLOW_EXPERIMENT_NAME\",\n",
    "        \"OLLAMA_BASE_URL\",\n",
    "        \"OLLAMA_MODEL\",\n",
    "        \"OPENAI_MODEL\",\n",
    "    ]\n",
    "\n",
    "    for env_var in required_env_vars:\n",
    "        assert env_var in os.environ, f\"{env_var} environment variable must be set\"\n",
    "    print(\"Environment variables are set\")\n",
    "    return True\n",
    "\n",
    "\n",
    "check_env_vars()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3e7f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup MLflow\n",
    "def setup_mlflow(tracking_uri, mlflow_experiment_name, active_model_name=None):\n",
    "    \"\"\"\n",
    "    function to setup mlflow\n",
    "    \"\"\"\n",
    "\n",
    "    if not tracking_uri:\n",
    "        raise ValueError(\"MLFLOW_TRACKING_URI environment variable must be set\")\n",
    "    mlflow.set_tracking_uri(tracking_uri)\n",
    "\n",
    "    exp_name = mlflow_experiment_name\n",
    "    client = MlflowClient()\n",
    "    exp = client.get_experiment_by_name(exp_name)\n",
    "\n",
    "    if exp is None:\n",
    "        mlflow.set_experiment(exp_name)\n",
    "    elif exp.lifecycle_stage == \"deleted\":\n",
    "        print(\"The experiment is deleted. Restoring it...\")\n",
    "        client.restore_experiment(exp.experiment_id)\n",
    "        mlflow.set_experiment(exp_name)\n",
    "    else:\n",
    "        mlflow.set_experiment(exp_name)\n",
    "\n",
    "    if active_model_name:\n",
    "        mlflow.set_active_model(name=active_model_name)\n",
    "\n",
    "    print(f\"tracking uri: {mlflow.get_tracking_uri()}\")\n",
    "    print(f\"experiment: {mlflow.get_experiment_by_name(mlflow_experiment_name)}\")\n",
    "    print(f\"active model: {mlflow.get_active_model_id()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dce9dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\"What was the company‚Äôs revenue in Q2?\"]\n",
    "ground_truth = [\"$25.3B\"]\n",
    "predicted_answers = [\"$25B\"]\n",
    "\n",
    "setup_mlflow(\n",
    "    tracking_uri=os.getenv(\"MLFLOW_TRACKING_URI\"),\n",
    "    mlflow_experiment_name=\"QA_Evaluation\",\n",
    "    # active_model_name=\"default_anonymous\",\n",
    ")\n",
    "\n",
    "\n",
    "with mlflow.start_run():\n",
    "    data = pd.DataFrame(\n",
    "        {\n",
    "            \"question\": questions,\n",
    "            \"ground_truth\": ground_truth,\n",
    "            \"predicted\": predicted_answers,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Evaluate QA model\n",
    "    # results = mlflow.evaluate(\n",
    "    #     data=data,\n",
    "    #     targets=\"ground_truth\",\n",
    "    #     predictions=\"predicted\",\n",
    "    #     model_type=\"question-answering\",\n",
    "\n",
    "    # )\n",
    "    results = mlflow.evaluate(\n",
    "        data=data,\n",
    "        targets=\"ground_truth\",\n",
    "        predictions=\"predicted\",\n",
    "        model_type=\"question-answering\",\n",
    "    )\n",
    "print(results.metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24f9d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_mlflow(\n",
    "    tracking_uri=os.getenv(\"MLFLOW_TRACKING_URI\"),\n",
    "    mlflow_experiment_name=os.getenv(\"MLFLOW_EXPERIMENT_NAME\", \"llm_tracing_ollama\"),\n",
    "    active_model_name=os.getenv(\"MLFLOW_ACTIVE_MODEL_NAME\", \"llama318b_model\"),\n",
    ")\n",
    "\n",
    "# Enable MLflow automatic tracing for OpenAI\n",
    "mlflow.openai.autolog()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4047d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic openai client request\n",
    "def basic_query_to_openai(query: str):\n",
    "    \"\"\"\n",
    "    This function is used to query the OpenAI API with a basic query. This is used to test the connection to the OpenAI API.\n",
    "    \"\"\"\n",
    "    client = OpenAI()\n",
    "    response = client.with_options(timeout=900.0).responses.create(\n",
    "        model=os.getenv(\"OPENAI_MODEL\"),\n",
    "        input=\"In two sentences, describe the biggest loss caused by the crop diseases in India by the farmers\",\n",
    "        # service_tier=\"flex\",\n",
    "    )\n",
    "    print(response.output_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3608d43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_timeout = httpx.Timeout(10.0, read=180.0)\n",
    "client = OpenAI(\n",
    "    base_url=os.getenv(\"OLLAMA_BASE_URL\"),  # The local Ollama REST endpoint\n",
    "    api_key=os.getenv(\"OPENAPI_KEY\"),\n",
    "    max_retries=0,\n",
    "    timeout=custom_timeout,\n",
    ")\n",
    "\n",
    "# response = client.chat.completions.create(\n",
    "#     model=os.getenv(\"OLLAMA_MODEL\"),\n",
    "#     messages=[\n",
    "#         {\"role\": \"system\", \"content\": \"You are a science teacher.\"},\n",
    "#         {\"role\": \"user\", \"content\": \"Why is the sky blue?\"},\n",
    "#     ],\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb556e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "@mlflow.trace\n",
    "def chat_with_ollama(messages):\n",
    "    response = client.chat.completions.create(\n",
    "        model=os.getenv(\"OLLAMA_MODEL\"),\n",
    "        messages=messages,  # timeout=180\n",
    "    )\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ff995d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def other_stats(response):\n",
    "    # print(response)\n",
    "    print(response.model_dump())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db496d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trace():\n",
    "    # Get the trace object just created\n",
    "    last_trace_id = mlflow.get_last_active_trace_id()\n",
    "    print(f\"Last trace ID: {last_trace_id}\")\n",
    "\n",
    "    if last_trace_id is None:\n",
    "        print(\"No trace found. Make sure MLflow tracing is enabled.\")\n",
    "    else:\n",
    "        trace = mlflow.get_trace(trace_id=last_trace_id)\n",
    "\n",
    "        if trace is None:\n",
    "            print(f\"Could not retrieve trace with ID: {last_trace_id}\")\n",
    "        elif trace.info is None:\n",
    "            print(\"Trace info is not available.\")\n",
    "        else:\n",
    "            # Check if token usage is available\n",
    "            if hasattr(trace.info, \"token_usage\") and trace.info.token_usage:\n",
    "                # Print the token usage\n",
    "                total_usage = trace.info.token_usage\n",
    "                print(\"== Total token usage: ==\")\n",
    "                print(f\"  Input tokens: {total_usage['input_tokens']}\")\n",
    "                print(f\"  Output tokens: {total_usage['output_tokens']}\")\n",
    "                print(f\"  Total tokens: {total_usage['total_tokens']}\")\n",
    "            else:\n",
    "                print(\"Token usage information not available in trace.info\")\n",
    "\n",
    "            # Print the token usage for each LLM call\n",
    "            if hasattr(trace, \"data\") and trace.data and hasattr(trace.data, \"spans\"):\n",
    "                print(\"\\n== Detailed usage for each LLM call: ==\")\n",
    "                found_usage = False\n",
    "                for span in trace.data.spans:\n",
    "                    if usage := span.get_attribute(\"mlflow.chat.tokenUsage\"):\n",
    "                        found_usage = True\n",
    "                        print(f\"{span.name}:\")\n",
    "                        print(f\"  Input tokens: {usage['input_tokens']}\")\n",
    "                        print(f\"  Output tokens: {usage['output_tokens']}\")\n",
    "                        print(f\"  Total tokens: {usage['total_tokens']}\")\n",
    "\n",
    "                if not found_usage:\n",
    "                    print(\"No token usage found in span attributes\")\n",
    "            else:\n",
    "                print(\"Trace data or spans not available\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63b4303",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_trace():\n",
    "    # Test the fix: Re-run the OpenAI call with tracing enabled\n",
    "    print(\"Making a new OpenAI call with MLflow tracing enabled...\")\n",
    "\n",
    "    response2 = client.chat.completions.create(\n",
    "        model=os.getenv(\"OLLAMA_MODEL\"),\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": \"What is machine learning?\"},\n",
    "        ],\n",
    "    )\n",
    "    print(response2.model_dump())\n",
    "    print(\"Response generated. Checking for trace...\")\n",
    "\n",
    "    # Now try to get the trace again\n",
    "    last_trace_id = mlflow.get_last_active_trace_id()\n",
    "    print(f\"New trace ID: {last_trace_id}\")\n",
    "\n",
    "    if last_trace_id:\n",
    "        trace = mlflow.get_trace(trace_id=last_trace_id)\n",
    "        if trace and trace.info:\n",
    "            print(\"‚úÖ Trace successfully retrieved!\")\n",
    "            print(f\"Trace status: {trace.info.status}\")\n",
    "            if hasattr(trace.info, \"token_usage\") and trace.info.token_usage:\n",
    "                print(f\"Token usage available: {trace.info.token_usage}\")\n",
    "            else:\n",
    "                print(\"Token usage not available in trace.info\")\n",
    "        else:\n",
    "            print(\"‚ùå Trace or trace.info still None\")\n",
    "    else:\n",
    "        print(\"‚ùå Still no trace ID found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9a4961",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trace_for_active_model(n: int = 1):\n",
    "    active_model_id = mlflow.get_active_model_id()\n",
    "    return mlflow.search_traces(model_id=active_model_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057115d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_single_line(s: str) -> str:\n",
    "    return \" \".join(s.split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9716199a",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "    \"What is the insecticide and fungicide chemicals used for leaf disease Black Rot in Tamil Nadu, India?\",\n",
    "    \"What are my organic options to cure the disease Black Rot in Tamil Nadu?\",\n",
    "    \"will this impact my paddy plants as well?\",\n",
    "]\n",
    "outputs = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854292f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a agriculture expert.\"},\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"{questions[0]}\",\n",
    "    },\n",
    "]\n",
    "try:\n",
    "    response = chat_with_ollama(messages)\n",
    "    outputs.append(response.choices[0].message.content)\n",
    "    other_stats(response)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71cfa1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a agriculture expert.\"},\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"{questions[1]}\",\n",
    "    },\n",
    "]\n",
    "try:\n",
    "    response = chat_with_ollama(messages)\n",
    "    outputs.append(response.choices[0].message.content)\n",
    "    other_stats(response)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59673f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a agriculture expert.\"},\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"{questions[2]}\",\n",
    "    },\n",
    "]\n",
    "try:\n",
    "    response = chat_with_ollama(messages)\n",
    "    outputs.append(response.choices[0].message.content)\n",
    "    other_stats(response)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d488ac37",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_response_raw = [\n",
    "    \"\"\"\n",
    "            Hey ‚Äî to give good advice, can you tell me which crop the ‚Äúblack rot‚Äù is on (for example, cabbage/crucifers, grape, citrus, etc.)? Different crops + pathogens need different chemicals. Meanwhile, here‚Äôs a general idea plus what Tamil Nadu Agricultural University (TNAU) recommends (for crucifers like cabbage) for black rot and similar leaf diseases.\n",
    "\n",
    "‚∏ª\n",
    "\n",
    "What is ‚ÄúBlack Rot‚Äù generally\n",
    "\t‚Ä¢\tIn crucifers (cabbage, cauliflower etc.), ‚Äúblack rot‚Äù is caused by Xanthomonas campestris pv. campestris, a bacterial pathogen. So antibiotics or copper-based bactericides are used, not just fungicides.\n",
    "\t‚Ä¢\tThere are also fungal diseases called ‚Äúleaf blight,‚Äù ‚Äúleaf spot,‚Äù etc., so need to be clear which you mean.\n",
    "\n",
    "‚∏ª\n",
    "\n",
    "TNAU recommendations (Cabbage / Crucifers in Tamil Nadu) for Black Rot (bacterial)\n",
    "\n",
    "From TNAU‚Äôs crop protection guide for cabbage:  Ôøº\n",
    "\t‚Ä¢\tSeed treatment: Dip seeds in streptomycin 100 parts per million (ppm) for 30 minutes.  Ôøº\n",
    "\t‚Ä¢\tFoliar sprays: Two sprays after planting and during head formation with a mixture of copper oxychloride + streptomycin (100 ppm) each time.  Ôøº\n",
    "\n",
    "So in this case, the chemical control is:\n",
    "\t‚Ä¢\tStreptomycin (an antibiotic)\n",
    "\t‚Ä¢\tCopper oxychloride (a copper-based bactericide/fungicide)\n",
    "\n",
    "‚∏ª\n",
    "\n",
    "Other chemicals used for leaf disease control (fungal/bacterial) in Tamil Nadu or similar regions\n",
    "\n",
    "Even though these are for leaf spot, blight, etc., many overlap with what could help prevent secondary fungal infections:\n",
    "\t‚Ä¢\tMancozeb ‚Äî commonly used for leaf spot, blight, etc.  Ôøº\n",
    "\t‚Ä¢\tCarbendazim ‚Äî a systemic fungicide used in various leaf spot/blight control.  Ôøº\n",
    "\t‚Ä¢\tCopper-based compounds ‚Äî e.g. copper oxychloride, copper hydroxide. These are useful for bacterial as well as fungal diseases.  Ôøº\n",
    "\n",
    "‚∏ª\n",
    "\n",
    "What to consider / use depending on the pathogen\n",
    "\t‚Ä¢\tIf it‚Äôs truly bacterial black rot (Xanthomonas in crucifers): use copper compounds + antibiotics (if allowed/legal).\n",
    "\t‚Ä¢\tIf fungal (leaf spot, anthracnose, etc.): use fungicides like Mancozeb, Carbendazim, or such, depending on fungicide registration and safety.\n",
    "\t‚Ä¢\tAlways follow label rates, waiting periods, resistance management (rotate chemicals), avoid spray drift, etc.\n",
    "\n",
    "‚∏ª\n",
    "\n",
    "If you tell me the crop and symptoms (what the spots look like, if there‚Äôs a smell, whether the veins turn black, etc.), I can give you a more specific list of insecticides/fungicides/antibiotics approved in Tamil Nadu (with dosages). Do you want me to pull that together?\n",
    "            \n",
    "            \"\"\",\n",
    "    \"\"\"\n",
    "            Got it üå± Thanks for clarifying ‚Äî you‚Äôre asking about organic ways to manage black rot (most often a bacterial disease on crucifers like cabbage/cauliflower, caused by Xanthomonas campestris). Since this is bacterial, chemical fungicides don‚Äôt really help, and organic control is more about prevention + cultural practices with a few allowed sprays.\n",
    "\n",
    "Here are your organic options, especially suited for Tamil Nadu conditions:\n",
    "\n",
    "‚∏ª\n",
    "\n",
    "üåø Organic & Eco-Friendly Management of Black Rot\n",
    "\n",
    "1. Seed & Seedling Care\n",
    "\t‚Ä¢\tHot water seed treatment: Soak seeds in water at 50 ¬∞C for 30 minutes ‚Üí kills bacteria hiding on the seed coat.\n",
    "\t‚Ä¢\tTrichoderma / Pseudomonas seed treatment: Coat seeds with Pseudomonas fluorescens powder (10 g/kg seed) ‚Äì this is widely used in Tamil Nadu organic farming.\n",
    "\n",
    "2. Soil & Nursery Management\n",
    "\t‚Ä¢\tAlways raise seedlings in disease-free soil or trays (avoid reusing infected soil).\n",
    "\t‚Ä¢\tApply neem cake or Pseudomonas fluorescens in the nursery bed to reduce pathogen survival.\n",
    "\n",
    "3. Field Practices\n",
    "\t‚Ä¢\tFollow 3-year crop rotation (avoid planting crucifers like cabbage, cauliflower, mustard, radish in the same plot repeatedly).\n",
    "\t‚Ä¢\tKeep good drainage and spacing ‚Äì wet, crowded plants spread bacteria faster.\n",
    "\t‚Ä¢\tRemove and burn infected leaves/plants as soon as you notice symptoms.\n",
    "\n",
    "4. Organic Sprays (allowed in organic farming)\n",
    "\t‚Ä¢\tNeem oil (2‚Äì3%): Has mild antibacterial effect and reduces pest stress (since insect wounds spread bacteria).\n",
    "\t‚Ä¢\tPanchagavya or Jeevamrutham foliar sprays: Boosts plant immunity.\n",
    "\t‚Ä¢\tGarlic or ginger extract sprays (10%) ‚Äì traditional practice in TN, with antibacterial properties.\n",
    "\t‚Ä¢\tCopper-based sprays (Bordeaux mixture / copper hydroxide): These are permitted in organic farming (under restricted use). They suppress bacterial population on leaves.\n",
    "\n",
    "5. Biological Control\n",
    "\t‚Ä¢\tRegular foliar sprays of Pseudomonas fluorescens @ 0.2% (available from TNAU and organic input shops in Tamil Nadu).\n",
    "‚Üí It competes with Xanthomonas and prevents spread.\n",
    "\n",
    "‚∏ª\n",
    "\n",
    "‚úÖ Best Integrated Organic Strategy in Tamil Nadu\n",
    "\t1.\tHot water treat seeds ‚Üí coat with Pseudomonas fluorescens.\n",
    "\t2.\tApply neem cake + Pseudomonas in nursery.\n",
    "\t3.\tUse wide spacing + good drainage.\n",
    "\t4.\tRemove diseased plants early.\n",
    "\t5.\tFoliar sprays of neem oil or Pseudomonas regularly, and copper hydroxide (if certified organic standards allow).\n",
    "\n",
    "‚∏ª\n",
    "\n",
    "Would you like me to make a simple spray schedule (month-wise) for Tamil Nadu cabbage/cauliflower under organic management, so you can follow step by step?\n",
    "            \n",
    "            \"\"\",\n",
    "    \"\"\"\n",
    "            Good question üëç ‚Äî I can see why you‚Äôre worried!\n",
    "\n",
    "The black rot disease in cabbage/cauliflower (crucifers) is caused by the bacterium Xanthomonas campestris pv. campestris. This pathogen is host-specific ‚Äî meaning it infects crucifer family plants (like cabbage, cauliflower, mustard, radish, knolkhol, etc.), but not rice (paddy).\n",
    "\n",
    "‚∏ª\n",
    "\n",
    "üåæ What about Paddy?\n",
    "\t‚Ä¢\tPaddy has its own bacterial diseases, like bacterial leaf blight (BLB) caused by Xanthomonas oryzae pv. oryzae.\n",
    "\t‚Ä¢\tEven though both are Xanthomonas, they are different strains (pathovars) and don‚Äôt jump from cabbage to rice.\n",
    "\n",
    "‚∏ª\n",
    "\n",
    "‚úÖ So the answer is:\n",
    "\t‚Ä¢\tNo direct impact ‚Äî your paddy plants won‚Äôt get infected from cabbage black rot.\n",
    "\t‚Ä¢\tBut, if you‚Äôre spraying copper-based sprays or neem oil in the same area, those won‚Äôt harm paddy (in fact, copper is sometimes used for BLB in rice too).\n",
    "\t‚Ä¢\tJust be careful about crop rotation ‚Äî don‚Äôt rotate crucifers with crucifers, but paddy after cabbage is totally safe.\n",
    "\n",
    "‚∏ª\n",
    "\n",
    "üëâ Do you want me to also share some organic tips for bacterial leaf blight in paddy (since it‚Äôs a common issue in Tamil Nadu)? That way, you‚Äôll have both cabbage and rice covered.\n",
    "            \n",
    "            \"\"\",\n",
    "]\n",
    "\n",
    "expected_response = [to_single_line(s) for s in expected_response_raw]\n",
    "\n",
    "expected_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c1cc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = pd.DataFrame(\n",
    "    {\n",
    "        \"user_query\": questions,\n",
    "        \"expected_response_from_judge\": expected_response,\n",
    "        \"generated_response\": outputs,\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad76ad6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scorers = [\n",
    "    RelevanceToQuery(),  # LLM as judge - relevance\n",
    "    RetrievalGroundedness(),  # For RAG - groundedness\n",
    "    # RetrievalRelevance(),  # RAG: passage relevance\n",
    "    RetrievalSufficiency(),\n",
    "    # Safety(),  # Safety metric\n",
    "    # Guidelines(),  # Customizable\n",
    "    Correctness(),  # Heuristic\n",
    "    ExpectationsGuidelines(),  # Heuristic\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ee5074",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_metrics_to_track = [\n",
    "    faithfulness(model=\"gateway:/openai-gpt-4o\"),\n",
    "    relevance(model=\"gateway:/openai-gpt-4o\"),\n",
    "    answer_correctness(model=\"gateway:/openai-gpt-4o\"),\n",
    "    answer_relevance(model=\"gateway:/openai-gpt-4o\"),\n",
    "    answer_similarity(model=\"gateway:/openai-gpt-4o\"),\n",
    "    # toxicity(),\n",
    "    # flesch_kincaid_grade_level(),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d892fa7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def old_evaluation_methods(data, targets, predictions, model_type):\n",
    "    results = mlflow.evaluate(\n",
    "        data=data,\n",
    "        targets=targets,\n",
    "        predictions=predictions,\n",
    "        model_type=model_type,\n",
    "    )\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cec4d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run() as evaluation_run:\n",
    "    eval_dataset_new = mlflow.data.from_pandas(\n",
    "        df=eval_df,\n",
    "        name=\"eval_dataset\",\n",
    "        targets=\"expected_response_from_judge\",\n",
    "        predictions=\"generated_response\",\n",
    "    )\n",
    "    mlflow.log_input(dataset=eval_dataset_new)\n",
    "    # Run the evaluation based on extra metrics\n",
    "    # Current active model will be automatically used\n",
    "\n",
    "    # ######### NOT WORKING\n",
    "    # result1 = old_evaluation_methods(\n",
    "    #     data=eval_df,\n",
    "    #     targets=\"expected_response_from_judge\",\n",
    "    #     predictions=\"generated_response\",\n",
    "    #     model_type=\"question-answering\",\n",
    "    # )\n",
    "    # result1.tables[\"eval_results_table\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb377cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result1 = mlflow.genai.evaluate(\n",
    "#     data=eval_dataset,\n",
    "#     # scorers=scorers,\n",
    "#     model_id=mlflow.get_active_model_id(),\n",
    "#     # predict_fn=\n",
    "# )\n",
    "\n",
    "#### deprecated\n",
    "# result2 = mlflow.evaluate(\n",
    "#     data=eval_dataset,\n",
    "#     # extra_metrics=[\n",
    "#     #     mlflow.metrics.genai.answer_correctness(model=\"gateway:/llama3.1:8b\"),\n",
    "#     #     mlflow.metrics.genai.answer_relevance(model=\"gateway:/llama3.1:8b\"),\n",
    "#     # ],\n",
    "#     # This is needed since answer_correctness looks for 'inputs' field\n",
    "#     evaluator_config={\"col_mapping\": {\"inputs\": \"messages\"}},\n",
    "#     model_type=\"question-answering\",\n",
    "# )\n",
    "\n",
    "# result2.tables[\"eval_results_table\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0963a4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cb31bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef41e71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
